---
layout: article
aside:
    toc: true
sidebar:
    nav: docs-en
title: 7. Higher-Order Derivatives
---

# Higher-Order Derivatives

5.6장까지는 gradient, 즉, 1차(first-order) 도함수(derivatives)에 대해서 논의했습니다. 하지만, 예를 들어, 2차 도함수가 필요한 최적화인 Newton's method를 사용하려는 경우와 같이 더 높은 차수의 도함수가 필요할 때가 있습니다. [5.1.1장]({{ site.baseurl }}/2022/07/18/ch5-1.html#taylor-series)에서는 polynomials를 사용하여 함수를 근사하는 Taylor series에 대해 살펴봤습니다. Multivaiate의 경우에도 동일하게 taylor series를 적용할 수 있습니다. 5.7장에서는 먼저 몇 가지 표기법을 정리한 다음, 이에 대해 자세히 살펴보도록 하겠습니다.

두 변수 $x, y$ 의 함수 $f:\mathbb{R}^2\rightarrow\mathbb{R}$ 이 있을 때, higher-order partial derivatives를 다음의 표기법을 사용하여 나타냅니다.

- $\frac{\partial^2f}{\partial x^2}$ : $x$ 에 대한 $f$ 의 second partial derivative
- $\frac{\partial^n f}{\partial x^n}$ : $x$ 에 대한 $f$ 의 $n$ th partial derivative
- $\frac{\partial^2f}{\partial y\partial x} = \frac{\partial}{\partial y}(\frac{\partial f}{\partial x})$ : x에 대해 first partial derivative 에서 y에 대한 fisrt partial derivative를 구한 것
- $\frac{\partial^2f}{\partial x\partial y} = \frac{\partial}{\partial x}(\frac{\partial f}{\partial y})$ : 위와 순서가 반대

*Hessian* 은 모든 second-order partial derivatives의 collection 입니다.

만약 $f(x, y)$ 가 두 번 연속적으로 미분이 가능한 함수라면, 다음의 식이 성립합니다.

$$ \frac{\partial^2f}{\partial x\partial y} = \frac{\partial^2f}{\partial y\partial x} \tag{5.146} $$

즉, 미분의 순서는 중요하지 않으며, 이에 대응되는 *Hessian matrix* 는 다음과 같이 symmetric 합니다.

$$ \boldsymbol{H} = \begin{bmatrix}\frac{\partial^2f}{\partial x^2}&\frac{\partial^2f}{\partial x\partial y}\\\frac{\partial^2f}{\partial x\partial y}&\frac{\partial^2f}{\partial y^2}\end{bmatrix} \tag{5.147} $$

Hessian은 $\nabla^2_{x,y}f(x, y)$ 로 표기합니다. 일반적으로 $\boldsymbol{x}\in\mathbb{R}^n$ 과 $f:\mathbb{R}^n\rightarrow \mathbb{R}$ 에 대해, Hessian은 $n\times n$ 행렬입니다. Hessian은 $(x,y)$ 주변에서 국부적으로(locally) 함수의 곡률(the curvature of the function)을 측정합니다.

*Remark* (Hessian of a Vector Field). 만약 함수 $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ 이 vector field라면, Hessian은 $(m\times n\times n)$ 텐서(tensor) 입니다.

